{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "In this Project, you will bring together many of the tools and techniques that you have learned throughout this course into a final project. You can choose from many different paths to get to the solution. \n",
    "\n",
    "### Business scenario\n",
    "\n",
    "You work for a training organization that recently developed an introductory course about machine learning (ML). The course includes more than 40 videos that cover a broad range of ML topics. You have been asked to create an application that will students can use to quickly locate and view video content by searching for topics and key phrases.\n",
    "\n",
    "You have downloaded all of the videos to an Amazon Simple Storage Service (Amazon S3) bucket. Your assignment is to produce a dashboard that meets your supervisorâ€™s requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project steps\n",
    "\n",
    "To complete this project, you will follow these steps:\n",
    "\n",
    "1. [Viewing the video files](#1.-Viewing-the-video-files)\n",
    "2. [Transcribing the videos](#2.-Transcribing-the-videos)\n",
    "3. [Normalizing the text](#3.-Normalizing-the-text)\n",
    "4. [Extracting key phrases and topics](#4.-Extracting-key-phrases-and-topics)\n",
    "5. [Creating the dashboard](#5.-Creating-the-dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information\n",
    "\n",
    "The following cell contains some information that might be useful as you complete this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = \"c56161a939430l3396553t1w744137092661-labbucket-rn642jaq01e9\"\n",
    "job_data_access_role = 'arn:aws:iam::744137092661:role/service-role/c56161a939430l3396553t1w7-ComprehendDataAccessRole-1P24MSS91ADHP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Installing all the necessary libraries\n",
    "!pip install moviepy\n",
    "!pip install SpeechRecognition\n",
    "!pip install pocketsphinx\n",
    "!pip install contractions\n",
    "!pip install keybert\n",
    "!pip install gradio\n",
    "\n",
    "#importing all the libraries used\n",
    "import subprocess\n",
    "import boto3\n",
    "import os\n",
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "import pocketsphinx\n",
    "import shutil\n",
    "from keybert import KeyBERT\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from keybert import KeyBERT\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Viewing the video files\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source video files are located in the following shared Amazon Simple Storage Service (Amazon S3) bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transcribing the videos\n",
    " ([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to implement your solution to transcribe the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "\n",
    "#making a list to hold the name of the movies\n",
    "import subprocess\n",
    "aws_command = \"aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/\"\n",
    "output = subprocess.check_output(aws_command, shell=True).decode()\n",
    "\n",
    "movie_list = []\n",
    "lines = output.strip().split('\\n')\n",
    "for line in lines:\n",
    "    parts = line.split()\n",
    "    if len(movie_list) == 0:\n",
    "        filename = parts[-2] + \" \"+parts[-1]\n",
    "        movie_list.append(filename)\n",
    "    else:\n",
    "        filename = parts[-1]\n",
    "        movie_list.append(filename)\n",
    "print(movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#downloading the videos from the S3 bucket\n",
    "import boto3\n",
    "import os\n",
    "s3 = boto3.resource(\"s3\")\n",
    "b = s3.Bucket(\"aws-tc-largeobjects\")\n",
    "obj_key = \"CUR-TF-200-ACMNLP-1/video/\"\n",
    "for i in movie_list:\n",
    "    object_key = obj_key + i \n",
    "    video_file = os.path.join(\"video\", i)\n",
    "    print(object_key)\n",
    "    b.download_file(Key = object_key,Filename = video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Converting the video into an audio file format\n",
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "file = \"video/\"\n",
    "for i in movie_list:\n",
    "    video_file = file + i\n",
    "    clip = mp.VideoFileClip(video_file)\n",
    "    audio = clip.audio\n",
    "    audio.write_audiofile(f\"{i}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Transcribing the audio\n",
    "import pocketsphinx\n",
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "recognizer = sr.Recognizer()\n",
    "for i in movie_list:\n",
    "    folder_path = \"text_files/\"\n",
    "    file_name = folder_path + i + \".txt\"\n",
    "    txt_file = open(file_name,\"w+\")\n",
    "    audio_file = i + \".wav\"\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        print(\"Transcribing audio: \", audio_file)\n",
    "        data = recognizer.record(source)\n",
    "    text = recognizer.recognize_sphinx(data)\n",
    "    txt_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalizing the text\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to perform any text normalization steps that are necessary for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "\n",
    "#Performing all text-preprocessing on all the documents\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re, string\n",
    "import contractions\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "def text_normalizing(text):\n",
    "    expanded_words = []\n",
    "    for i in text.split():\n",
    "        expanded_words.append(contractions.fix(i))\n",
    "    text = \" \".join(expanded_words)\n",
    "    text = text.lower()\n",
    "    punctuation = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    stop_word = stopwords.words('english')\n",
    "    text = re.sub(punctuation,'',text )\n",
    "    text.strip()\n",
    "    normalized_text = []\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in tokens:\n",
    "        if i not in stop_word:\n",
    "            normalized_text.append(i)\n",
    "    #print(normalized_text)\n",
    "    lemmatize = []\n",
    "    lm = WordNetLemmatizer()\n",
    "    for i in normalized_text:\n",
    "        lemmatize.append(lm.lemmatize(i))\n",
    "    final_text = \" \".join(lemmatize)\n",
    "    return final_text\n",
    "    \n",
    "    \n",
    "for i in sorted(os.listdir(\"text_files/\")):\n",
    "    with open(\"text_files/\" + i,\"r\") as file:\n",
    "        data = file.read()\n",
    "        data = text_normalizing(data)\n",
    "        with open(\"normalized_text_files/\" + i,\"w+\") as normalized_file:\n",
    "            normalized_file.write(data)\n",
    "            normalized_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting key phrases and topics\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to extract the key phrases and topics from the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "\n",
    "#To check the score for each keywords in the video\n",
    "from keybert import KeyBERT\n",
    "key = KeyBERT()\n",
    "keyword_score = {}\n",
    "for i in sorted(os.listdir(\"normalized_text_files\")):\n",
    "    with open(\"normalized_text_files/\" + i,\"r\") as file:\n",
    "        doc = file.read()\n",
    "        keywords = key.extract_keywords(doc)\n",
    "        print(i+\": \",keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Implementing keyword and topic extractions for a given topic fed from the chatbot dashboard\n",
    "def key_word_extraction(text):\n",
    "    key = KeyBERT()\n",
    "    keywords = key.extract_keywords(text)\n",
    "    return keywords\n",
    "\n",
    "def locate_video(input):\n",
    "    score = 0\n",
    "    video = None\n",
    "    for i in sorted(os.listdir(\"normalized_text_files\")):\n",
    "        with open(\"normalized_text_files/\" + i,\"r\") as file:\n",
    "            doc = file.read()\n",
    "            key_words = key_word_extraction(doc)\n",
    "            matching_score = 0\n",
    "            for key, scores in input:\n",
    "                for j, k in key_words:\n",
    "                    if key in j:\n",
    "                        matching_score = matching_score + k\n",
    "            if matching_score > score:\n",
    "                score = matching_score\n",
    "                video = i\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the dashboard\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to create the dashboard for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "\n",
    "# Recommend video based on topics given by the user\n",
    "def chatbot(message, history):\n",
    "  # Default response if no keyword matches\n",
    "    default_response = \"No video found\"\n",
    "    text = message\n",
    "    input_text = key_word_extraction(message)\n",
    "    recommended_video = locate_video(input_text)\n",
    "    if recommended_video:\n",
    "        return f\"recommended video: {recommended_video}\"\n",
    "    else:\n",
    "        return default_response\n",
    "\n",
    "gr.ChatInterface(\n",
    "    chatbot,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Type the topic you want to learn\", container=False, scale=7),\n",
    "    title=\"Locate Video\",\n",
    "    description=\"Which video topics are you looking for?\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"Computer Vision\", \"Speech Recognition\", \"Classification\", \"Regression\"],\n",
    "    cache_examples=True,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
